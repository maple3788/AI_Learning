{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1.ÂΩìinput‰∏∫categorical data, output ‰∏∫ real-valueÂèØ‰ª•‰ΩøÁî®ÊòØ‰ªÄ‰πàÁõ∏ÂÖ≥ÊÄßÂàÜÊûêÊñπÊ≥ï?\n",
    "\n",
    "Okay, this is a very classic problem in data science (DS) practice.\n",
    "\n",
    "When the input (independent variable) is **Categorical Data** and the output (dependent variable) is a **Real-value**, we cannot use methods like the Pearson correlation coefficient, which measures the linear relationship between two continuous variables.\n",
    "\n",
    "In this situation, the core analytical idea is to **compare whether there is a significant difference in the mean of the real-value output across different categories**. If a significant difference exists, we can conclude that there is an association between the categorical variable and the continuous variable.\n",
    "\n",
    "Here are the main correlation analysis methods you can use:\n",
    "\n",
    "### 1. Analysis of Variance (ANOVA)\n",
    "\n",
    "This is the most common and central method.\n",
    "\n",
    "* **Core Idea**: ANOVA determines if a categorical variable has a significant effect on a continuous variable by testing whether the variation in means **between different groups** is significantly greater than the variation **within each group**.\n",
    "* **How to Interpret**:\n",
    "    * It calculates an **F-statistic** and a **p-value**.\n",
    "    * **If the p-value is very small** (e.g., less than 0.05), we can reject the null hypothesis that \"all group means are equal\" and conclude that there is a significant statistical association between the categorical variable and the continuous variable.\n",
    "* **Example**:\n",
    "    * **Input (Categorical)**: User's education level (e.g., elementary school, high school, university, master's, doctorate)\n",
    "    * **Output (Real-value)**: User's annual income\n",
    "    * ANOVA can test whether there is a significant difference in the average annual income among people with different education levels. If so, it indicates that \"education level\" and \"annual income\" are correlated.\n",
    "\n",
    "### 2. Eta Squared (Œ∑¬≤)\n",
    "\n",
    "While ANOVA tells us if the association is **significant**, Eta squared tells us how **strong** that association is. It is often used as a supplementary measure of effect size for ANOVA.\n",
    "\n",
    "* **Core Idea**: Eta squared measures the proportion of the total variance in the output variable that can be explained by the input categorical variable.\n",
    "* **How to Interpret**:\n",
    "    * The value of Œ∑¬≤ ranges from **0 to 1**.\n",
    "    * A value **closer to 1** indicates that the categorical variable explains more of the variance in the continuous variable, meaning a stronger association.\n",
    "    * A value **closer to 0** indicates a weaker association.\n",
    "* **Example**: In the education and income example above, if Œ∑¬≤ = 0.65, we could say that about 65% of the variance in annual income can be explained by differences in education level. This is a very strong association.\n",
    "\n",
    "### 3. t-test - A Special Case\n",
    "\n",
    "You can use a t-test when your categorical variable has **only two categories**.\n",
    "\n",
    "* **Core Idea**: A t-test is specifically designed to compare the means of two groups to see if they are significantly different. It is essentially a special case of ANOVA for two groups.\n",
    "* **Example**:\n",
    "    * **Input (Categorical)**: Smoker (Yes, No)\n",
    "    * **Output (Real-value)**: Lung capacity\n",
    "    * A t-test can determine if there is a significant difference in the average lung capacity between smokers and non-smokers.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "| Analysis Goal | Method | Key Metrics | Interpretation |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Check if association is significant** | **ANOVA** | F-statistic, p-value | p-value < 0.05 usually means significant |\n",
    "| | (For two categories) **t-test** | t-statistic, p-value | p-value < 0.05 usually means significant |\n",
    "| **Measure association strength** | **Eta Squared (Œ∑¬≤)** | Œ∑¬≤ (value between 0-1) | Higher value means stronger association |\n",
    "\n",
    "For the daily work of a data scientist, when encountering this type of data, **the preferred method is to run an ANOVA and calculate Eta squared simultaneously**. This way, you can determine both if the categorical feature is useful (from the p-value) and how impactful it is (from Œ∑¬≤), providing a solid basis for subsequent feature selection and model analysis.\n",
    "\n",
    "# üìä Pearson Correlation ‚Äî Detailed but Concise\n",
    "\n",
    "## üß† Formula\n",
    "$$\n",
    "r = \\frac{\\text{cov}(X, Y)}{\\sigma_X \\sigma_Y}\n",
    "$$\n",
    "\n",
    "### üîπ Variables Explained\n",
    "- **X, Y** ‚Äî Two continuous variables (e.g., height and weight)\n",
    "- **cov(X, Y)** ‚Äî Covariance between X and Y, showing how they vary together\n",
    "- **œÉ‚Çì, œÉ·µß** ‚Äî Standard deviations of X and Y\n",
    "- **r** ‚Äî Pearson correlation coefficient\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Meaning of r\n",
    "- **Range:** -1 ‚â§ r ‚â§ 1\n",
    "  - **r = 1** ‚Üí perfect positive linear relationship\n",
    "  - **r = -1** ‚Üí perfect negative linear relationship\n",
    "  - **r = 0** ‚Üí no linear relationship\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Strength Guide\n",
    "| r value | Strength | Direction |\n",
    "|----------|-----------|------------|\n",
    "| 0.7‚Äì1.0 | Strong | Positive |\n",
    "| 0.3‚Äì0.7 | Moderate | Positive |\n",
    "| 0.0‚Äì0.3 | Weak | Positive |\n",
    "| -0.3‚Äì0.0 | Weak | Negative |\n",
    "| -0.7‚Äì-0.3 | Moderate | Negative |\n",
    "| -1.0‚Äì-0.7 | Strong | Negative |\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Example (Python)\n",
    "```python\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Example data\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [2, 4, 6, 8, 10]\n",
    "\n",
    "r, p = pearsonr(x, y)\n",
    "print(f\"r: {r}, p-value: {p}\")\n",
    "# r ‚Üí Correlation coefficient (e.g., r = 0.99 ‚Üí very strong positive correlation)\n",
    "# p-value ‚Üí Probability that correlation happened by chance (p < 0.05 ‚Üí statistically significant)\n",
    "```\n",
    "\n",
    "# üéØ Relationship between p-value in Correlation and ANOVA\n",
    "\n",
    "- Both **p-values** represent the **probability that the observed result happened by chance** under the **null hypothesis**.\n",
    "- In both cases:\n",
    "  - **Null hypothesis (H‚ÇÄ):** no real relationship or difference exists.\n",
    "  - **Alternative hypothesis (H‚ÇÅ):** there is a real effect.\n",
    "\n",
    "| Test Type | Null Hypothesis | What p-value Measures | Interpretation (p < 0.05) |\n",
    "|------------|----------------|------------------------|----------------------------|\n",
    "| Pearson Correlation | X and Y are not correlated | Chance of seeing such a high correlation if X and Y are unrelated | Significant correlation |\n",
    "| ANOVA | All group means are equal | Chance of seeing such large between-group differences if means were equal | Significant difference between groups |\n",
    "\n",
    "So yes ‚Äî both p-values tell you **‚Äúhow likely this result is just luck.‚Äù**"
   ],
   "id": "827fe4344bea874b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2.Ê¢ØÂ∫¶ÊòØ‰ªÄ‰πàÔºüÂ¶Ç‰ΩïËÆ°ÁÆó?\n",
    "Of course, let's discuss the second key concept: the gradient.\n",
    "\n",
    "### 1. What is a Gradient?\n",
    "\n",
    "In machine learning and mathematics, the **gradient** is a vector that points in the direction of the **fastest increase** of a function at a specific point. The **magnitude** (or length) of this vector represents the rate of that increase‚Äîessentially, how steep the slope is at that point.\n",
    "\n",
    "You can visualize it by imagining you are standing on a mountain:\n",
    "* **The direction of the gradient**: Points directly up the steepest path from where you are standing.\n",
    "* **The opposite direction of the gradient (-Gradient)**: Points directly down the steepest path.\n",
    "* **The magnitude of the gradient**: Represents how steep that path is. The steeper the slope, the longer the gradient vector.\n",
    "\n",
    "In machine learning model training, our goal is to **minimize a Loss Function**. The loss function is like a vast mountain range, and we want to find the lowest point in a valley. Therefore, we are not interested in the direction of the fastest ascent, but rather the direction of the **fastest descent**. This direction is precisely the **opposite of the gradient**.\n",
    "\n",
    "The process of finding the minimum of the loss function by calculating the gradient and moving in the opposite direction is the core idea behind the **Gradient Descent** algorithm.\n",
    "\n",
    "### 2. How to Calculate it?\n",
    "\n",
    "The gradient is calculated by finding the **partial derivative** of the function with respect to each of its variables.\n",
    "\n",
    "Assume we have a function $f(w_1, w_2, ..., w_n)$, which depends on multiple variables (in machine learning, these variables are the model's weights $w_1, w_2$, etc.).\n",
    "\n",
    "The gradient of this function $f$, denoted as $\\nabla f$, is a vector composed of all its partial derivatives:\n",
    "\n",
    "$$\n",
    "\\nabla f = \\begin{pmatrix} \\frac{\\partial f}{\\partial w_1} \\\\ \\frac{\\partial f}{\\partial w_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial w_n} \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Here, the symbol $\\frac{\\partial f}{\\partial w_1}$ represents the partial derivative of the function $f$ with respect to the variable $w_1$. To calculate it, we treat all other variables ($w_2, ..., w_n$) as constants and differentiate only with respect to $w_1$.\n",
    "\n",
    "---\n",
    "\n",
    "#### **A Simple Calculation Example**\n",
    "\n",
    "Let's assume our model has only one weight $w$ and one bias $b$, and the Loss function ($L$) is a simple squared error:\n",
    "$L(w, b) = (w \\cdot x + b - y)^2$\n",
    "\n",
    "Here, $x$ and $y$ are a single sample from our training data (the input and the true label), so they are known constants. We need to calculate the gradient of the loss function $L$ with respect to the model parameters $w$ and $b$.\n",
    "\n",
    "**The gradient $\\nabla L$ is a vector containing two partial derivatives:**\n",
    "\n",
    "$$\n",
    "\\nabla L = \\begin{pmatrix} \\frac{\\partial L}{\\partial w} \\\\ \\frac{\\partial L}{\\partial b} \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**Calculation Steps:**\n",
    "\n",
    "1.  **Calculate the partial derivative with respect to $w$, $\\frac{\\partial L}{\\partial w}$** (treating $b$ as a constant):\n",
    "    * Using the Chain Rule:\n",
    "    $$\n",
    "    \\frac{\\partial L}{\\partial w} = 2 \\cdot (w \\cdot x + b - y) \\cdot \\frac{\\partial}{\\partial w}(w \\cdot x + b - y)\n",
    "    $$\n",
    "    * In the term $\\frac{\\partial}{\\partial w}(w \\cdot x + b - y)$, only $w \\cdot x$ depends on $w$, so its derivative is $x$.\n",
    "    * Result:\n",
    "    $$\n",
    "    \\frac{\\partial L}{\\partial w} = 2 \\cdot (w \\cdot x + b - y) \\cdot x\n",
    "    $$\n",
    "\n",
    "2.  **Calculate the partial derivative with respect to $b$, $\\frac{\\partial L}{\\partial b}$** (treating $w$ as a constant):\n",
    "    * Again, using the Chain Rule:\n",
    "    $$\n",
    "    \\frac{\\partial L}{\\partial b} = 2 \\cdot (w \\cdot x + b - y) \\cdot \\frac{\\partial}{\\partial b}(w \\cdot x + b - y)\n",
    "    $$\n",
    "    * In the term $\\frac{\\partial}{\\partial b}(w \\cdot x + b - y)$, only $b$ depends on $b$, so its derivative is 1.\n",
    "    * Result:\n",
    "    $$\n",
    "    \\frac{\\partial L}{\\partial b} = 2 \\cdot (w \\cdot x + b - y) \\cdot 1\n",
    "    $$\n",
    "\n",
    "**Finally, the gradient vector is:**\n",
    "\n",
    "$$\n",
    "\\nabla L = \\begin{pmatrix} 2x(wx + b - y) \\\\ 2(wx + b - y) \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "In actual model training, we would substitute the current numerical values of $w, b, x,$ and $y$ into this formula to get a concrete vector. The model then updates the parameters $w$ and $b$ by taking a small step in the **opposite** direction of this gradient vector. This process is repeated iteratively until the minimum of the loss function is found."
   ],
   "id": "420740516326de7c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3.‰ªÄ‰πàÊÉÖÂÜµ‰ºöÂØºËá¥Ê¢ØÂ∫¶ÁàÜÁÇ∏ÂíåÊ∂àÂ§±?\n",
    "\n",
    "Certainly. Both vanishing and exploding gradients are common problems in training deep neural networks, especially Recurrent Neural Networks (RNNs). They both arise from the same fundamental cause: the way gradients are propagated backward through the network using the **chain rule**.\n",
    "\n",
    "In a deep network, the gradient of the loss function with respect to the weights of an early layer is calculated by multiplying the gradients of all the subsequent layers.\n",
    "\n",
    "Imagine a simple deep network where the gradient for an early layer is a product like this:\n",
    "$$\\frac{\\partial L}{\\partial w_{early}} = \\frac{\\partial L}{\\partial a_{final}} \\cdot \\frac{\\partial a_{final}}{\\partial a_{final-1}} \\cdot \\ldots \\cdot \\frac{\\partial a_{early+1}}{\\partial a_{early}}$$\n",
    "\n",
    "This is a long chain of multiplications. The value of each term $\\frac{\\partial a_{k+1}}{\\partial a_k}$ (which is related to the weights and the activation function's derivative at layer $k$) determines what happens to the overall product.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Vanishing Gradients\n",
    "\n",
    "The vanishing gradient problem occurs when the gradients become extremely small as they are propagated backward, effectively approaching zero.\n",
    "\n",
    "#### **What Causes It?**\n",
    "\n",
    "This happens when the terms being multiplied in the chain rule are **consistently less than 1**. Multiplying many numbers that are smaller than 1 together results in an exponentially small number.\n",
    "\n",
    "**Key culprits include:**\n",
    "\n",
    "1.  **Activation Functions:** Certain activation functions \"squash\" their input into a small range. Their derivatives are also small.\n",
    "    * **Sigmoid Function:** Its derivative has a maximum value of only 0.25. When you are outside the central active region, the derivative is very close to 0.\n",
    "    * **Tanh Function:** Its derivative is slightly better, with a maximum value of 1.0, but for most inputs, the derivative is still a value less than 1.\n",
    "2.  **Weight Initialization:** If the weights of the network are initialized to be small values (e.g., with a standard deviation much less than 1), the products will also tend to be small.\n",
    "\n",
    "#### **What is the Consequence?**\n",
    "\n",
    "* **Slow or Stalled Training:** The weights and biases of the initial layers (the layers farthest from the output) are not updated effectively because their gradients are nearly zero.\n",
    "* **Failure to Learn Long-Range Dependencies:** The early layers are crucial for learning basic, low-level features. If they don't learn, the entire network cannot learn complex patterns. In RNNs, this means the model cannot capture relationships between distant words or events in a sequence.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Exploding Gradients\n",
    "\n",
    "The exploding gradient problem is the opposite: the gradients become excessively large as they are propagated backward, eventually resulting in `NaN` (Not a Number) values.\n",
    "\n",
    "#### **What Causes It?**\n",
    "\n",
    "This happens when the terms being multiplied in the chain rule are **consistently greater than 1**. Multiplying many numbers larger than 1 together results in an exponentially large number.\n",
    "\n",
    "**Key culprits include:**\n",
    "\n",
    "1.  **Weight Initialization:** This is the most common cause. If the weights are initialized with large values, the gradient values can accumulate and grow uncontrollably during backpropagation.\n",
    "2.  **A Deep Network Architecture:** Even with weights around 1.0, if you have a very deep network, the repeated multiplication can still lead to an explosion. For example, $(1.15)^{100}$ is a very large number.\n",
    "\n",
    "#### **What is the Consequence?**\n",
    "\n",
    "* **Unstable Training:** The model's weights will change drastically with each update. The loss function may fluctuate wildly or go to `NaN` after just a few iterations.\n",
    "* **Numerical Overflow:** The large gradient values can exceed the floating-point precision limits of the hardware, leading to `NaN` values and causing the training process to crash. The model completely fails to learn.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "| Problem | Cause | Why it Happens | Result |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Vanishing Gradients** | Gradient values shrink exponentially towards 0. | Repeated multiplication of numbers **< 1** (e.g., sigmoid derivatives). | Early layers learn very slowly or not at all. Model cannot learn long-range dependencies. |\n",
    "| **Exploding Gradients** | Gradient values grow exponentially towards infinity. | Repeated multiplication of numbers **> 1** (e.g., large weight initializations). | Training is unstable; loss becomes `NaN`. The model diverges and fails to train. |"
   ],
   "id": "2f7f9af85585f7ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4.ÊÄé‰πàËØäÊñ≠biasÂíåvariance?\n",
    "\n",
    "Diagnosing bias and variance is a critical step in improving a machine learning model's performance. The diagnosis is primarily done by comparing the model's error on the **training dataset** versus its error on a **validation (or test) dataset**.\n",
    "\n",
    "Let's assume we have a desired \"base\" error rate, which represents the best possible performance (e.g., human-level performance or the irreducible error).\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Understanding the Key Metrics\n",
    "\n",
    "To diagnose the problem, you need to look at these two values:\n",
    "\n",
    "* **Training Error:** How well the model performs on the data it was trained on. A low training error means the model has learned the patterns in the training data.\n",
    "* **Validation Error (or Dev/Test Error):** How well the model performs on new, unseen data. This indicates the model's ability to generalize.\n",
    "\n",
    "The difference between these two error rates is the key to our diagnosis.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. The Four Scenarios\n",
    "\n",
    "By comparing the training and validation errors, we can identify one of four scenarios:\n",
    "\n",
    "#### **Scenario 1: High Bias (Underfitting)**\n",
    "\n",
    "This is the simplest case to diagnose. The model is too simple to capture the underlying patterns in the data.\n",
    "\n",
    "* **Symptoms:**\n",
    "    * **High Training Error:** The model performs poorly even on the data it has already seen.\n",
    "    * **High Validation Error:** The validation error is also high and is very close to the training error.\n",
    "* **Diagnosis:** If your model isn't even capable of fitting the training data well, it is suffering from high bias. It is \"underfitting\" the data.\n",
    "* **Example:** A linear regression model trying to fit a complex, U-shaped curve.\n",
    "\n",
    "#### **Scenario 2: High Variance (Overfitting)**\n",
    "\n",
    "This is the most common problem in deep learning. The model has learned the training data too well, including its noise and random fluctuations.\n",
    "\n",
    "* **Symptoms:**\n",
    "    * **Low Training Error:** The model performs exceptionally well on the training data.\n",
    "    * **High Validation Error:** The model performs poorly on unseen data. There is a large gap between the training and validation error.\n",
    "* **Diagnosis:** If the model aces the training set but fails on the validation set, it is suffering from high variance. It is not generalizing and is \"overfitting\" the training data.\n",
    "* **Example:** A very deep decision tree that has created a specific path for almost every single data point in the training set.\n",
    "\n",
    "#### **Scenario 3: High Bias AND High Variance**\n",
    "\n",
    "This is a more complex and problematic scenario. The model is wrong, but it's also inconsistently wrong.\n",
    "\n",
    "* **Symptoms:**\n",
    "    * **High Training Error:** The model performs poorly on the training data.\n",
    "    * **Even Higher Validation Error:** The validation error is significantly worse than the training error.\n",
    "* **Diagnosis:** The model is too simple to capture the correct patterns (high bias), but it has also learned some noise from the training data that doesn't generalize (high variance).\n",
    "* **Example:** Trying to fit a straight line to a sine wave, but the line is skewed by a few noisy outliers in the training data. The model is wrong (it's a line, not a curve), and it's also sensitive to the specific training data points.\n",
    "\n",
    "#### **Scenario 4: Low Bias and Low Variance (Good Fit)**\n",
    "\n",
    "This is the ideal state we want to achieve.\n",
    "\n",
    "* **Symptoms:**\n",
    "    * **Low Training Error:** The model fits the training data well.\n",
    "    * **Low Validation Error:** The validation error is also low and is only slightly higher than the training error.\n",
    "* **Diagnosis:** The model has successfully learned the underlying patterns and generalizes well to new data.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Table for Diagnosis\n",
    "\n",
    "| Scenario | Training Error | Validation Error | Diagnosis | Nickname |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| 1 | High | High (similar to training error) | **High Bias** | Underfitting |\n",
    "| 2 | Low | High (much higher than training) | **High Variance** | Overfitting |\n",
    "| 3 | High | Very High (much higher than training) | **High Bias & High Variance** | Worst Case |\n",
    "| 4 | Low | Low (slightly higher than training) | **Low Bias & Low Variance** | Ideal Model |\n",
    "\n",
    "### Using Learning Curves for Diagnosis\n",
    "\n",
    "Another powerful tool is to plot **learning curves**. These graphs show the model's error (e.g., loss or accuracy) on both the training and validation sets as a function of the number of training examples.\n",
    "\n",
    "* **High Bias Learning Curve:** Both training and validation errors will be high and will plateau quickly. Adding more data will not help because the model is fundamentally too simple to learn from it.\n",
    "* **High Variance Learning Curve:** There will be a large, persistent gap between the training error (which will be low) and the validation error (which will be high). As you add more data, the gap will tend to shrink, which indicates that gathering more data is a viable solution."
   ],
   "id": "334e77c3963c6025"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 5.Ê¢ØÂ∫¶‰∏ãÈôçÂíåOLSÁöÑÂå∫Âà´ÊòØ‰ªÄ‰πàÔºü\n",
    "Gradient Descent and Ordinary Least Squares (OLS) can both be used to find the optimal parameters for a linear regression model, but they are fundamentally different methods in their approach and application.\n",
    "\n",
    "**Ordinary Least Squares (OLS)** is an analytical method, while **Gradient Descent** is an iterative optimization algorithm.\n",
    "\n",
    "Here is a breakdown of their key differences:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Core Approach: Analytical vs. Iterative\n",
    "\n",
    "* **Ordinary Least Squares (OLS):** OLS provides a **direct, closed-form solution**. It finds the model parameters by solving a set of linear equations that directly minimize the sum of the squared differences between the predicted and actual values (the \"least squares\"). This is a purely mathematical derivation.\n",
    "    * **Analogy:** It's like solving a simple equation like `2x = 10` by directly calculating `x = 10 / 2`. You get the exact answer in one step.\n",
    "    * **The Formula:** The parameters (coefficients `Œ≤`) are calculated at once using a matrix formula known as the normal equation:\n",
    "        $$\\beta = (X^T X)^{-1} X^T y$$\n",
    "\n",
    "* **Gradient Descent (GD):** GD is an **iterative optimization algorithm**. It doesn't solve for the answer directly. Instead, it starts with a random guess for the parameters and takes small, repeated steps to find the minimum of the loss function (which, for linear regression, is the same sum of squared errors that OLS minimizes).\n",
    "    * **Analogy:** It's like finding the lowest point in a valley while blindfolded. You start somewhere, feel the slope (the gradient) around you, and take a small step in the steepest downward direction. You repeat this process until you reach the bottom.\n",
    "    * **The Process:**\n",
    "        1.  Initialize parameters (weights) with random values.\n",
    "        2.  Calculate the gradient of the loss function.\n",
    "        3.  Update the parameters by taking a small step in the opposite direction of the gradient.\n",
    "        4.  Repeat steps 2 and 3 until the loss stops decreasing (convergence).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Application Scope\n",
    "\n",
    "* **OLS:** Is **specifically designed for linear regression**. It cannot be directly used for more complex models like logistic regression, neural networks, or support vector machines. Its application is narrow but highly effective for linear models.\n",
    "\n",
    "* **Gradient Descent:** Is a **general-purpose optimization algorithm**. It can be used to find the minimum of almost any differentiable function. This makes it extremely versatile and the foundational optimizer for a vast range of machine learning models, including nearly all of deep learning.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Computational Complexity and Scalability\n",
    "\n",
    "* **OLS:** The calculation involves inverting a matrix (`(X^T X)^{-1}`). Matrix inversion is a computationally expensive operation, typically with a complexity of about $O(n^3)$, where `n` is the number of features.\n",
    "    * **Pro:** Very fast for datasets with a small number of features.\n",
    "    * **Con:** It becomes extremely slow or computationally infeasible for datasets with a very large number of features (e.g., hundreds of thousands).\n",
    "\n",
    "* **Gradient Descent:** The complexity of each iteration is typically $O(m \\cdot n)$, where `m` is the number of data points and `n` is the number of features.\n",
    "    * **Pro:** Scales much better to datasets with a massive number of features. Variants like Stochastic Gradient Descent (SGD) are even more efficient as they update parameters using only one or a few data points at a time.\n",
    "    * **Con:** May require many iterations to converge. Finding the right learning rate can be tricky.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Need for Feature Scaling\n",
    "\n",
    "* **OLS:** Does not require feature scaling. The analytical solution will be the same regardless of the scale of the input features.\n",
    "\n",
    "* **Gradient Descent:** Is very sensitive to the scale of the features. If one feature has a much larger range than others, the loss function becomes a steep, narrow ellipse, and GD will take a long, zigzagging path to the minimum. Therefore, **feature scaling (like standardization or normalization) is almost always a required preprocessing step** for Gradient Descent.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Table\n",
    "\n",
    "| Feature | Ordinary Least Squares (OLS) | Gradient Descent (GD) |\n",
    "| :--- | :--- | :--- |\n",
    "| **Method Type** | Analytical, closed-form solution | Iterative optimization algorithm |\n",
    "| **How it Works** | Solves a matrix equation directly (Normal Equation) | Takes repeated steps \"downhill\" on the loss function |\n",
    "| **Solution Quality** | Provides the exact, optimal solution | Provides a very good approximation of the optimal solution |\n",
    "| **Application** | Specific to Linear Regression | General-purpose; used in most ML/DL models |\n",
    "| **Scalability** | Poor for many features (due to matrix inversion) | Excellent; scales well to millions of features |\n",
    "| **Feature Scaling**| Not required | Required for good performance |\n",
    "| **Hyperparameters**| None | Requires a learning rate (`alpha`) and number of iterations |\n",
    "\n",
    "**Conclusion:** For a standard linear regression problem with a manageable number of features, **OLS is often the preferred method** because it is fast, simple, and gives the exact solution without needing to tune any hyperparameters. However, for almost any other machine learning problem or for linear regression on very high-dimensional data, **Gradient Descent (and its variants) is the necessary and more scalable approach.**"
   ],
   "id": "16ba2cd9de5f7b8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T02:08:58.083255Z",
     "start_time": "2025-10-17T02:08:57.474349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# To determine if a categorical feature is related to a continuous target, we can use an Analysis of Variance (ANOVA) test. The core idea is to see if the means of the continuous variable are significantly different across the categories.\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# --- Sample Data ---\n",
    "# Imagine we have data on car prices from three different brands.\n",
    "# Input (Categorical): car_brand\n",
    "# Output (Real-value): price\n",
    "\n",
    "# Prices for Brand A cars (mean around 25k)\n",
    "prices_brand_a = np.random.normal(25000, 3000, 50)\n",
    "# Prices for Brand B cars (mean around 26k - similar to A)\n",
    "prices_brand_b = np.random.normal(26000, 3000, 50)\n",
    "# Prices for Brand C cars (mean around 35k - different)\n",
    "prices_brand_c = np.random.normal(35000, 3000, 50)\n",
    "\n",
    "# --- ANOVA Test ---\n",
    "# The f_oneway function performs a 1-way ANOVA.\n",
    "f_statistic, p_value = stats.f_oneway(prices_brand_a, prices_brand_b, prices_brand_c)\n",
    "\n",
    "print(f\"F-Statistic: {f_statistic:.2f}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# --- Interpretation ---\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nThe p-value is less than 0.05, so we reject the null hypothesis.\")\n",
    "    print(\"Conclusion: There is a significant difference in prices between the car brands. The 'brand' is a useful feature. ‚úÖ\")\n",
    "else:\n",
    "    print(\"\\nThe p-value is greater than 0.05.\")\n",
    "    print(\"Conclusion: There is no significant difference in prices. The 'brand' may not be a useful feature. ‚ùå\")"
   ],
   "id": "9659576f3fb9c301",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 188.32\n",
      "P-value: 2.8083476971042504e-41\n",
      "\n",
      "The p-value is less than 0.05, so we reject the null hypothesis.\n",
      "Conclusion: There is a significant difference in prices between the car brands. The 'brand' is a useful feature. ‚úÖ\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üß© ANOVA ‚Äî F-Statistic and P-Value (Concise)\n",
    "\n",
    "## 1Ô∏è‚É£ What ANOVA Does\n",
    "Tests if **group means differ significantly** (e.g., car prices across brands).\n",
    "\n",
    "- **H‚ÇÄ:** All means are equal ‚Üí ŒºA = ŒºB = ŒºC\n",
    "- **H‚ÇÅ:** At least one mean is different\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ F-Statistic\n",
    "$$\n",
    "F = \\frac{\\text{Between-group variance}}{\\text{Within-group variance}}\n",
    "$$\n",
    "\n",
    "- **Between-group variance:** how far each group mean is from overall mean (signal)\n",
    "- **Within-group variance:** spread within each group (noise)\n",
    "- **Large F ‚Üí means differ; small F ‚Üí means similar**\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ P-Value\n",
    "Probability of observing the F-statistic if H‚ÇÄ were true.\n",
    "\n",
    "| p-value | Interpretation |\n",
    "|----------|----------------|\n",
    "| < 0.05 | Reject H‚ÇÄ ‚Äî groups differ significantly ‚úÖ |\n",
    "| ‚â• 0.05 | Fail to reject H‚ÇÄ ‚Äî no significant difference ‚ùå |\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Example\n",
    "\n",
    "‚Üí Between-group differences are much larger than within-group noise ‚Üí reject H‚ÇÄ.\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Formula Summary\n",
    "$$\n",
    "MS_B = \\frac{SS_B}{k-1}, \\quad MS_W = \\frac{SS_W}{N-k}, \\quad F = \\frac{MS_B}{MS_W}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary Table\n",
    "| Term | Meaning | Interpretation |\n",
    "|------|----------|----------------|\n",
    "| F-statistic | Ratio of signal to noise | Large ‚Üí significant difference |\n",
    "| P-value | Prob. of seeing this F if H‚ÇÄ true | Small ‚Üí reject H‚ÇÄ |\n"
   ],
   "id": "7a614051b425c719"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T07:29:32.747097Z",
     "start_time": "2025-10-17T07:29:32.743676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Single Data Point and Initial Parameters ---\n",
    "x = 2.0  # Input feature\n",
    "y = 5.0  # True label\n",
    "\n",
    "# Initial random guess for parameters\n",
    "w = 0.5\n",
    "b = 1.0\n",
    "\n",
    "# --- Forward Pass: Make a prediction ---\n",
    "prediction = w * x + b\n",
    "print(f\"Initial Prediction: {prediction}\")\n",
    "\n",
    "# --- Calculate Loss (Squared Error) ---\n",
    "loss = (prediction - y)**2\n",
    "print(f\"Initial Loss: {loss:.2f}\")\n",
    "\n",
    "# --- Backward Pass: Calculate the Gradient ---\n",
    "# This is the core of the calculation.\n",
    "grad_w = 2 * x * (prediction - y) # dL/dw\n",
    "grad_b = 2 * (prediction - y)     # dL/db\n",
    "\n",
    "# The gradient is a vector of these partial derivatives\n",
    "gradient = (grad_w, grad_b)\n",
    "\n",
    "print(f\"\\nGradient with respect to w (dL/dw): {grad_w:.2f}\")\n",
    "print(f\"Gradient with respect to b (dL/db): {grad_b:.2f}\")\n",
    "print(f\"Gradient Vector ‚àáL = ({grad_w:.2f}, {grad_b:.2f})\")\n",
    "print(\"\\nInterpretation: To decrease the loss, we should decrease 'w' and 'b' (since their gradients are negative).\")"
   ],
   "id": "8d2c0790afd0d35a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Prediction: 2.0\n",
      "Initial Loss: 9.00\n",
      "\n",
      "Gradient with respect to w (dL/dw): -12.00\n",
      "Gradient with respect to b (dL/db): -6.00\n",
      "Gradient Vector ‚àáL = (-12.00, -6.00)\n",
      "\n",
      "Interpretation: To decrease the loss, we should decrease 'w' and 'b' (since their gradients are negative).\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T07:30:46.956495Z",
     "start_time": "2025-10-17T07:30:46.952333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Simulation Parameters ---\n",
    "num_layers = 50\n",
    "initial_gradient = 1.0\n",
    "\n",
    "# --- Scenario 1: Vanishing Gradient ---\n",
    "# Caused by small weights (<1) and activation derivatives (<1), like sigmoid\n",
    "w_small = 0.5\n",
    "activation_derivative_small = 0.25 # Max derivative of sigmoid is 0.25\n",
    "\n",
    "vanishing_grad = initial_gradient\n",
    "for i in range(num_layers):\n",
    "    vanishing_grad *= w_small * activation_derivative_small\n",
    "    if (i+1) % 10 == 0:\n",
    "      print(f\"Layer {i+1}, Vanishing Gradient: {vanishing_grad}\")\n",
    "\n",
    "print(\"\\nResult: The gradient shrinks exponentially to almost zero. üìâ\\n\")\n",
    "\n",
    "# --- Scenario 2: Exploding Gradient ---\n",
    "# Caused by large weights (>1)\n",
    "w_large = 1.5\n",
    "# Assume activation derivative is 1 (like ReLU for positive inputs)\n",
    "activation_derivative_large = 1.0\n",
    "\n",
    "exploding_grad = initial_gradient\n",
    "for i in range(num_layers):\n",
    "    exploding_grad *= w_large * activation_derivative_large\n",
    "    if (i+1) % 10 == 0:\n",
    "        # Using scientific notation for large numbers\n",
    "        print(f\"Layer {i+1}, Exploding Gradient: {exploding_grad:e}\")\n",
    "\n",
    "print(\"\\nResult: The gradient grows exponentially to an enormous value. üìà\")"
   ],
   "id": "da9828b74a99b21b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 10, Vanishing Gradient: 9.313225746154785e-10\n",
      "Layer 20, Vanishing Gradient: 8.673617379884035e-19\n",
      "Layer 30, Vanishing Gradient: 8.077935669463161e-28\n",
      "Layer 40, Vanishing Gradient: 7.52316384526264e-37\n",
      "Layer 50, Vanishing Gradient: 7.006492321624085e-46\n",
      "\n",
      "Result: The gradient shrinks exponentially to almost zero. üìâ\n",
      "\n",
      "Layer 10, Exploding Gradient: 5.766504e+01\n",
      "Layer 20, Exploding Gradient: 3.325257e+03\n",
      "Layer 30, Exploding Gradient: 1.917511e+05\n",
      "Layer 40, Exploding Gradient: 1.105733e+07\n",
      "Layer 50, Exploding Gradient: 6.376215e+08\n",
      "\n",
      "Result: The gradient grows exponentially to an enormous value. üìà\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T07:31:21.421661Z",
     "start_time": "2025-10-17T07:31:19.716773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- Generate Sample Non-linear Data ---\n",
    "np.random.seed(0)\n",
    "X = np.linspace(-3, 3, 100).reshape(-1, 1)\n",
    "y = np.sin(X).ravel() + np.random.normal(0, 0.2, 100)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# --- Scenario 1: High Bias (Underfitting) ---\n",
    "# A simple linear model trying to fit a sine wave.\n",
    "model_bias = LinearRegression()\n",
    "model_bias.fit(X_train, y_train)\n",
    "\n",
    "train_error_bias = mean_squared_error(y_train, model_bias.predict(X_train))\n",
    "val_error_bias = mean_squared_error(y_val, model_bias.predict(X_val))\n",
    "\n",
    "print(f\"--- High Bias (Underfitting) ---\")\n",
    "print(f\"Training Error: {train_error_bias:.3f}\")\n",
    "print(f\"Validation Error: {val_error_bias:.3f}\")\n",
    "print(\"Diagnosis: Both errors are high. The model is too simple. üßê\\n\")\n",
    "\n",
    "# --- Scenario 2: High Variance (Overfitting) ---\n",
    "# A very complex polynomial model that can memorize the training data.\n",
    "model_variance = make_pipeline(PolynomialFeatures(degree=20), LinearRegression())\n",
    "model_variance.fit(X_train, y_train)\n",
    "\n",
    "train_error_var = mean_squared_error(y_train, model_variance.predict(X_train))\n",
    "val_error_var = mean_squared_error(y_val, model_variance.predict(X_val))\n",
    "\n",
    "print(f\"--- High Variance (Overfitting) ---\")\n",
    "print(f\"Training Error: {train_error_var:.3f}\")\n",
    "print(f\"Validation Error: {val_error_var:.3f}\")\n",
    "print(\"Diagnosis: Training error is very low, but validation error is high. The model doesn't generalize. ü§Ø\")\n",
    "\n",
    "# --- Plotting the models ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(X_train, y_train, label='Training Data', color='blue', alpha=0.5)\n",
    "plt.plot(X, model_bias.predict(X), color='red', label='High Bias Model (Underfit)')\n",
    "plt.plot(np.sort(X_train, axis=0), model_variance.predict(np.sort(X_train, axis=0)), color='green', label='High Variance Model (Overfit)')\n",
    "plt.title(\"Bias vs. Variance Diagnosis\")\n",
    "plt.legend()\n",
    "plt.ylim(-2, 2)\n",
    "plt.show()"
   ],
   "id": "80eaed1d60676063",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- High Bias (Underfitting) ---\n",
      "Training Error: 0.233\n",
      "Validation Error: 0.149\n",
      "Diagnosis: Both errors are high. The model is too simple. üßê\n",
      "\n",
      "--- High Variance (Overfitting) ---\n",
      "Training Error: 0.026\n",
      "Validation Error: 0.049\n",
      "Diagnosis: Training error is very low, but validation error is high. The model doesn't generalize. ü§Ø\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T07:32:59.627933Z",
     "start_time": "2025-10-17T07:32:59.568936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "\n",
    "# --- Generate Sample Linear Data ---\n",
    "X, y = make_regression(n_samples=200, n_features=1, noise=20, random_state=42)\n",
    "\n",
    "# OLS requires unscaled data\n",
    "# SGD performs best with scaled data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- Method 1: Ordinary Least Squares (Analytical Solution) ---\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X, y)\n",
    "\n",
    "print(\"--- OLS (Analytical) ---\")\n",
    "print(f\"Coefficient: {ols_model.coef_[0]:.2f}\")\n",
    "print(f\"Intercept: {ols_model.intercept_:.2f}\")\n",
    "print(\"Finds the exact solution in one step. No hyperparameters to tune.\\n\")\n",
    "\n",
    "# --- Method 2: Stochastic Gradient Descent (Iterative Solution) ---\n",
    "# Requires tuning hyperparameters like learning rate (eta0) and iterations (max_iter)\n",
    "sgd_model = SGDRegressor(max_iter=1000, tol=1e-3, eta0=0.01, random_state=42)\n",
    "sgd_model.fit(X_scaled, y)\n",
    "\n",
    "print(\"--- Gradient Descent (Iterative) ---\")\n",
    "# The coefficient is for the *scaled* data, so we un-scale it to compare\n",
    "# coef_unscaled = coef_scaled / scale_\n",
    "unscaled_coef = sgd_model.coef_[0] / scaler.scale_[0]\n",
    "print(f\"Coefficient (unscaled): {unscaled_coef:.2f}\")\n",
    "print(f\"Intercept: {sgd_model.intercept_[0]:.2f}\")\n",
    "print(\"Iteratively approaches a solution that is very close to the OLS one.\")"
   ],
   "id": "ec71b7437407ae27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- OLS (Analytical) ---\n",
      "Coefficient: 87.00\n",
      "Intercept: 2.86\n",
      "Finds the exact solution in one step. No hyperparameters to tune.\n",
      "\n",
      "--- Gradient Descent (Iterative) ---\n",
      "Coefficient (unscaled): 86.99\n",
      "Intercept: -0.66\n",
      "Iteratively approaches a solution that is very close to the OLS one.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T07:47:10.365544Z",
     "start_time": "2025-10-17T07:47:10.360263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Generate dummy data ---\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(5, 2) * 10   # 5 samples, 2 features\n",
    "true_w = np.array([[2.0], [3.0]])\n",
    "true_b = 5.0\n",
    "y = X @ true_w + true_b + np.random.randn(5, 1)  # add a little noise\n",
    "\n",
    "# --- Option 1: Compute bias separately ---\n",
    "# Closed-form OLS for weights (without bias)\n",
    "X_mean = X.mean(axis=0)\n",
    "y_mean = y.mean()\n",
    "\n",
    "# Center X and y\n",
    "X_centered = X - X_mean\n",
    "y_centered = y - y_mean\n",
    "\n",
    "# Compute weights using centered data\n",
    "w = np.linalg.inv(X_centered.T @ X_centered) @ X_centered.T @ y_centered\n",
    "\n",
    "# Compute bias\n",
    "b = y_mean - X_mean @ w\n",
    "\n",
    "print(\"Option 1 - Separate bias:\")\n",
    "print(\"Weights:\", w.ravel())\n",
    "print(\"Bias:\", b.item(), \"\\n\")\n",
    "\n",
    "# --- Option 2: Include bias term in X ---\n",
    "X_aug = np.hstack([np.ones((X.shape[0], 1)), X])  # add bias column\n",
    "w_aug = np.linalg.inv(X_aug.T @ X_aug) @ X_aug.T @ y\n",
    "\n",
    "print(\"Option 2 - Augmented X:\")\n",
    "print(\"Bias:\", w_aug[0, 0])\n",
    "print(\"Weights:\", w_aug[1:, 0])"
   ],
   "id": "767b61a39287337e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option 1 - Separate bias:\n",
      "Weights: [2.15623657 2.98028589]\n",
      "Bias: 4.405993838972105 \n",
      "\n",
      "Option 2 - Augmented X:\n",
      "Bias: 4.405993838972088\n",
      "Weights: [2.15623657 2.98028589]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1.‰ªÄ‰πàÊòØinformation Gain?\n",
    "This is a core concept for **Decision Tree** algorithms. üå≥\n",
    "\n",
    "In short: **Information Gain** is a metric that measures how much a feature *reduces uncertainty* (or \"impurity\") about the data.\n",
    "\n",
    "When building a decision tree, the algorithm must decide which feature to use for splitting the data at each node. It chooses the feature that provides the **highest Information Gain**, as this feature does the best job of separating the data into \"purer\" groups.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Understanding \"Uncertainty\" (Entropy)\n",
    "\n",
    "To understand Information Gain, you must first understand **Entropy**.\n",
    "\n",
    "* **Entropy** is a measure of randomness, impurity, or uncertainty in a dataset. The higher the entropy, the more \"mixed\" the data is.\n",
    "* **High Entropy (Maximum Uncertainty)** ü§Ø: Imagine a dataset of 10 coins, with 5 heads and 5 tails. If you pick one at random, you have no idea what you'll get. This is maximum entropy (entropy = 1).\n",
    "* **Low Entropy (Low Uncertainty)** ü§î: A dataset of 10 coins with 9 heads and 1 tail. You are *pretty sure* you'll get heads. This is low entropy.\n",
    "* **Zero Entropy (No Uncertainty)** ‚úÖ: A dataset of 10 coins with 10 heads. You are 100% certain you'll get heads. This is zero entropy (entropy = 0).\n",
    "\n",
    "The goal of a decision tree is to split the data until all leaf nodes have **zero entropy** (or as low as possible).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. What is Information Gain?\n",
    "\n",
    "**Information Gain** is the change in entropy from before to after splitting the data on a feature.\n",
    "\n",
    "**Information Gain = Entropy(Before Split) - Weighted Average Entropy(After Split)**\n",
    "\n",
    "The `Entropy(Before Split)` is the entropy of the parent node. The `Weighted Average Entropy(After Split)` is the sum of the entropies of all child nodes, weighted by how many data points went into each child node.\n",
    "\n",
    "#### The Formula\n",
    "\n",
    "$$\n",
    "\\text{Information Gain}(S, A) = \\text{Entropy}(S) - \\sum_{v \\in \\text{Values}(A)} \\frac{|S_v|}{|S|} \\cdot \\text{Entropy}(S_v)\n",
    "$$\n",
    "\n",
    "* $S$ is the current dataset (parent node).\n",
    "* $A$ is the feature we are testing for the split (e.g., \"Outlook\").\n",
    "* $\\text{Entropy}(S)$ is the entropy of the parent node.\n",
    "* $\\text{Values}(A)$ are the possible values of feature A (e.g., \"Sunny\", \"Rainy\").\n",
    "* $S_v$ is the subset of data where feature A has value $v$ (e.g., all \"Sunny\" data).\n",
    "* $\\frac{|S_v|}{|S|}$ is the *weight* of that child node (proportion of data points in it).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. A Simple Example\n",
    "\n",
    "Let's decide if we should **\"Play Tennis\"**.\n",
    "\n",
    "**Dataset (S):** 10 days\n",
    "* 5 days \"Play\"\n",
    "* 5 days \"Don't Play\"\n",
    "* **Entropy(S) = High (Maximum uncertainty)**\n",
    "\n",
    "We have two features to split on: \"Outlook\" and \"Humidity\".\n",
    "\n",
    "#### Split 1: Using Feature A (\"Outlook\")\n",
    "\n",
    "* **Child 1 (Outlook=Sunny):** 6 days total.\n",
    "    * 5 \"Play\", 1 \"Don't Play\"  ->  **Very Low Entropy** (almost pure)\n",
    "* **Child 2 (Outlook=Rainy):** 4 days total.\n",
    "    * 0 \"Play\", 4 \"Don't Play\"  ->  **Zero Entropy** (perfectly pure)\n",
    "\n",
    "* **Gain(Outlook)** = `Entropy(S)` - `[ (6/10) * Entropy(Sunny) + (4/10) * Entropy(Rainy) ]`\n",
    "* **Gain(Outlook)** = `High` - `[ (0.6) * Very Low + (0.4) * Zero ]`\n",
    "* This results in a **LARGE** Information Gain.\n",
    "\n",
    "#### Split 2: Using Feature B (\"Humidity\")\n",
    "\n",
    "* **Child 1 (Humidity=High):** 5 days total.\n",
    "    * 2 \"Play\", 3 \"Don't Play\"  ->  **High Entropy** (still very mixed)\n",
    "* **Child 2 (Humidity=Normal):** 5 days total.\n",
    "    * 3 \"Play\", 2 \"Don't Play\"  ->  **High Entropy** (also very mixed)\n",
    "\n",
    "* **Gain(Humidity)** = `Entropy(S)` - `[ (5/10) * Entropy(High) + (5/10) * Entropy(Normal) ]`\n",
    "* **Gain(Humidity)** = `High` - `[ (0.5) * High + (0.5) * High ]`\n",
    "* This results in a **VERY SMALL** (or near zero) Information Gain.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Conclusion\n",
    "\n",
    "**Gain(Outlook) >> Gain(Humidity)**\n",
    "\n",
    "The Information Gain from splitting on \"Outlook\" is much higher than splitting on \"Humidity\".\n",
    "\n",
    "Therefore, the decision tree algorithm (like ID3) will choose **\"Outlook\"** as the first feature to split on (the root node), because it does the best job of reducing uncertainty and separating the data into pure groups."
   ],
   "id": "1cc828992f5dbd3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2.‰ªÄ‰πàÊòØGini index?\n",
    "The **Gini Index**, or more accurately **Gini Impurity**, is another metric used in decision tree algorithms (like CART) to measure the \"impurity\" or \"mixed-ness\" of a node.\n",
    "\n",
    "It is a popular alternative to **Entropy** (which is used for Information Gain) because it is computationally faster.\n",
    "\n",
    "In short: **Gini Impurity measures the probability of misclassifying a randomly chosen element from the dataset if it were randomly labeled according to the class distribution in that node.**\n",
    "\n",
    "A **lower Gini Index** is better, meaning the node is \"purer.\"\n",
    "\n",
    "---\n",
    "\n",
    "### 1. How to Interpret the Gini Index Value\n",
    "\n",
    "The Gini Index ranges from 0 to (1 - 1/k), where k is the number of classes. For a simple two-class problem, the range is 0 to 0.5.\n",
    "\n",
    "* **Gini = 0 (Perfect Purity)** ‚úÖ\n",
    "    * This means all elements in the node belong to a single class.\n",
    "    * *Example:* A node with 10 \"Play\" and 0 \"Don't Play\".\n",
    "    * The probability of misclassification is 0%.\n",
    "\n",
    "* **Gini = 0.5 (Maximum Impurity, for 2 classes)** ü§Ø\n",
    "    * This means the elements are perfectly mixed (50/50).\n",
    "    * *Example:* A node with 5 \"Play\" and 5 \"Don't Play\".\n",
    "    * This is the worst-case scenario for a binary split.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. The Formula\n",
    "\n",
    "The Gini Impurity is calculated as:\n",
    "\n",
    "$$\n",
    "Gini = 1 - \\sum_{i=1}^{k} (p_i)^2\n",
    "$$\n",
    "\n",
    "* $k$ is the number of classes.\n",
    "* $p_i$ is the probability (or proportion) of items in the node belonging to class $i$.\n",
    "\n",
    "The term $\\sum (p_i)^2$ represents the probability of *correctly* classifying an element if you guess based on the node's distribution. Therefore, $1 - (\\text{that probability})$ gives you the probability of *misclassification*.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Calculation Examples (for 2 classes)\n",
    "\n",
    "Let's use the 10-day \"Play Tennis\" dataset.\n",
    "\n",
    "**Example 1: A Perfectly Pure Node (Gini = 0)**\n",
    "* Data: 10 \"Play\", 0 \"Don't Play\"\n",
    "* $p_{\\text{play}} = 10/10 = 1.0$\n",
    "* $p_{\\text{dont\\_play}} = 0/10 = 0.0$\n",
    "* $Gini = 1 - [ (1.0)^2 + (0.0)^2 ] = 1 - [ 1 + 0 ] = 0$\n",
    "\n",
    "**Example 2: A Perfectly Mixed Node (Gini = 0.5)**\n",
    "* Data: 5 \"Play\", 5 \"Don't Play\"\n",
    "* $p_{\\text{play}} = 5/10 = 0.5$\n",
    "* $p_{\\text{dont\\_play}} = 5/10 = 0.5$\n",
    "* $Gini = 1 - [ (0.5)^2 + (0.5)^2 ] = 1 - [ 0.25 + 0.25 ] = 1 - 0.5 = 0.5$\n",
    "\n",
    "**Example 3: A Moderately Impure Node**\n",
    "* Data: 8 \"Play\", 2 \"Don't Play\"\n",
    "* $p_{\\text{play}} = 8/10 = 0.8$\n",
    "* $p_{\\text{dont\\_play}} = 2/10 = 0.2$\n",
    "* $Gini = 1 - [ (0.8)^2 + (0.2)^2 ] = 1 - [ 0.64 + 0.04 ] = 1 - 0.68 = 0.32$\n",
    "    *(This node is \"purer\" than the 50/50 mix, as 0.32 < 0.5)*\n",
    "\n",
    "---\n",
    "\n",
    "### 4. How Decision Trees Use Gini (Gini Gain)\n",
    "\n",
    "Just like the ID3 algorithm uses *Information Gain* (based on Entropy), the **CART algorithm** uses **Gini Impurity** to decide on the best split.\n",
    "\n",
    "It calculates the **Gini Gain** (or \"Reduction in Impurity\") for each possible split.\n",
    "\n",
    "**Gini Gain = Gini(Parent) - Weighted Average Gini(Children)**\n",
    "\n",
    "The algorithm picks the feature and split value that **maximizes the Gini Gain** (which is the same as minimizing the weighted average Gini Impurity of the children).\n",
    "\n",
    "* **Why is it faster than Entropy?**\n",
    "    * The Gini formula only requires simple squaring.\n",
    "    * The Entropy formula requires a logarithm (`log(p)`) calculation, which is more computationally expensive.\n",
    "\n",
    "In practice, trees built using Gini or Entropy are very similar, so Gini is a common and efficient default."
   ],
   "id": "4e9799dfe6dbdb23"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3.GBDTÁöÑÂ∑•‰ΩúÂéüÁêÜ, ‰∏∫‰ªÄ‰πàGBDTÊòØÂú®boosting gradient?\n",
    "\n",
    "GBDT (Gradient Boosting Decision Tree) is a powerful machine learning ensemble method that builds a strong predictive model by sequentially combining many weak models, which are typically decision trees.\n",
    "\n",
    "To understand it, let's break down its name:\n",
    "* **Decision Tree:** The individual \"weak learner\" models being combined. They are usually shallow trees (called \"stumps\").\n",
    "* **Boosting:** The ensemble technique. It's a sequential process where each new model is built to correct the errors of the previous ones.\n",
    "* **Gradient:** This is GBDT's special ingredient. Instead of just correcting simple errors, it corrects the **gradient of the loss function**, making it a much more flexible and powerful framework.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. The Working Principle of GBDT (How it Works)\n",
    "\n",
    "GBDT builds its model step-by-step. Imagine you are trying to predict house prices (a regression task).\n",
    "\n",
    "#### **Step 1: Start with an Initial Prediction (F‚ÇÄ)**\n",
    "\n",
    "* The first model is very simple: it's just the average of all the target values. For example, if the average house price in your dataset is $300k, your initial prediction for *every* house is $300k.\n",
    "* This initial model is obviously not very good. It has a lot of errors.\n",
    "\n",
    "#### **Step 2: Calculate the Residuals**\n",
    "\n",
    "* For each house in the training set, calculate the error of the current model. This error is called the **residual**.\n",
    "* **Residual = Actual Price - Predicted Price**\n",
    "* *Example:* If a house's actual price is $350k, the residual is $350k - $300k = $50k. If another house is $280k, its residual is $280k - $300k = -$20k.\n",
    "* These residuals represent what the current model `F‚ÇÄ` got wrong.\n",
    "\n",
    "#### **Step 3: Train a New Weak Learner (a Decision Tree) on the Residuals**\n",
    "\n",
    "* This is the most critical step. You train a new decision tree (`h‚ÇÅ`) not to predict the house prices, but to predict the **residuals** from Step 2.\n",
    "* The goal of this new tree is to learn the *error patterns* of the previous model. So, for the house that was off by +$50k, this tree will try to predict \"+$50k\".\n",
    "\n",
    "#### **Step 4: Update the Main Model**\n",
    "\n",
    "* You update your overall model by adding the prediction of the new tree (`h‚ÇÅ`) to the previous model (`F‚ÇÄ`).\n",
    "* To prevent overfitting and control the learning process, you multiply the new tree's prediction by a small number called the **learning rate** (`eta` or `Œ±`).\n",
    "* **New Model (F‚ÇÅ) = Old Model (F‚ÇÄ) + learning_rate * New Tree (h‚ÇÅ)**\n",
    "* *Example:* `F‚ÇÅ(x) = $300k + 0.1 * h‚ÇÅ(x)`\n",
    "* Now, when you predict the price for the house that was off by +$50k, the new tree `h‚ÇÅ` might predict, say, \"$48k\". Your new overall prediction becomes `$300k + 0.1 * $48k = $304.8k`. You are now closer to the actual price of $350k.\n",
    "\n",
    "#### **Step 5: Repeat**\n",
    "\n",
    "* You repeat steps 2, 3, and 4 for many iterations (e.g., 100 times):\n",
    "    1.  Calculate the new residuals: `Actual Price - F‚ÇÅ(x)`\n",
    "    2.  Train a new tree (`h‚ÇÇ`) on these new residuals.\n",
    "    3.  Update the model: `F‚ÇÇ(x) = F‚ÇÅ(x) + learning_rate * h‚ÇÇ(x)`\n",
    "    4.  ...and so on.\n",
    "\n",
    "Each new tree focuses on the remaining errors, gradually improving the overall model until the errors are minimized.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Why GBDT is \"Boosting the Gradient\"\n",
    "\n",
    "The explanation above uses \"residuals\" which is easy to understand. However, the true power of GBDT comes from a more general idea: **gradient descent**.\n",
    "\n",
    "The \"residual\" (`Actual - Predicted`) is a special case that only works for a specific loss function: **Mean Squared Error (MSE)**.\n",
    "\n",
    "* Loss Function (MSE): $L(y, F(x)) = \\frac{1}{2}(y - F(x))^2$\n",
    "* The **gradient** of this loss function with respect to the model's prediction $F(x)$ is:\n",
    "    $$\\frac{\\partial L}{\\partial F(x)} = -(y - F(x))$$\n",
    "* The **negative gradient** is therefore:\n",
    "    $$- \\frac{\\partial L}{\\partial F(x)} = y - F(x)$$\n",
    "\n",
    "**This is the \"Aha!\" moment.** The negative gradient of the squared error loss function is exactly the residual!\n",
    "\n",
    "#### The Generalization\n",
    "\n",
    "GBDT generalizes this concept. Instead of being limited to MSE, it can work with *any* differentiable loss function (e.g., Log Loss for classification, Mean Absolute Error, etc.).\n",
    "\n",
    "So, the GBDT algorithm is actually:\n",
    "\n",
    "1.  Start with an initial model `F‚ÇÄ`.\n",
    "2.  For each iteration `m = 1 to M`:\n",
    "    a.  Calculate the **negative gradient** of the loss function with respect to the previous model's predictions, $F_{m-1}(x)$. These are called the \"pseudo-residuals\".\n",
    "    b.  Train a new decision tree `h_m` to predict these **pseudo-residuals (the negative gradients)**.\n",
    "    c.  Find the best multiplier (`gamma`) for this tree's output to minimize the overall loss.\n",
    "    d.  Update the model: $F_m(x) = F_{m-1}(x) + \\text{learning_rate} \\cdot \\gamma \\cdot h_m(x)$\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "GBDT is not just correcting simple errors. It is performing a form of **gradient descent in function space**.\n",
    "\n",
    "* In traditional gradient descent, you update *parameters* (like weights `w`) by taking a small step in the direction of the negative gradient.\n",
    "* In GBDT, you are updating a *function* (the model `F(x)`) by adding another function (the weak tree `h(x)`) that points in the direction of the negative gradient.\n",
    "\n",
    "This is why it's called **Gradient** Boosting. It boosts the model's performance by sequentially adding weak learners that are trained to approximate the **gradient** of the loss function, ensuring the model improves in the direction that most rapidly reduces the overall loss."
   ],
   "id": "3992dd6b89bcb444"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4.XGBoost ÂíåGBDTÁöÑÂå∫Âà´ÔºåÂêÑËá™ÁöÑ‰ºòÂäø?\n",
    "XGBoost (eXtreme Gradient Boosting) is not a fundamentally different algorithm from GBDT. Instead, it is a highly optimized and feature-rich **implementation** of the Gradient Boosting framework. Think of GBDT as the original concept and XGBoost as the high-performance, supercharged version.\n",
    "\n",
    "Almost everything that is a weakness in the standard GBDT framework is addressed and improved upon in XGBoost.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Differences: GBDT vs. XGBoost\n",
    "\n",
    "#### 1. Regularization: Preventing Overfitting\n",
    "\n",
    "* **Standard GBDT:** Has no built-in regularization. It is prone to overfitting, which is typically controlled only by shallow tree depth, a learning rate, and the number of estimators.\n",
    "* **XGBoost:** Includes both **L1 (Lasso) and L2 (Ridge) regularization** terms in its objective function. This penalizes model complexity (both the number of leaves and the magnitude of the leaf weights), which significantly reduces overfitting and improves generalization. This is one of the most important improvements.\n",
    "\n",
    "#### 2. Objective Function: Taylor Expansion\n",
    "\n",
    "* **Standard GBDT:** Uses only the **first derivative (the Gradient)** of the loss function to guide the model. It's essentially a form of gradient descent.\n",
    "* **XGBoost:** Uses a **second-order Taylor expansion** of the loss function. This means it uses both the **first derivative (Gradient)** and the **second derivative (Hessian)**.\n",
    "    * **Analogy:** Think of GBDT as finding the minimum of a curve by only knowing the *slope* (gradient). XGBoost is like knowing both the *slope* and the *curvature* (Hessian), which allows it to find a more direct and accurate path to the minimum. This leads to better convergence and often higher accuracy.\n",
    "\n",
    "#### 3. Handling Missing Values (Sparsity Awareness)\n",
    "\n",
    "* **Standard GBDT:** Does not have a built-in method for handling missing values. You must pre-process your data using imputation (e.g., filling with mean, median, etc.) before training.\n",
    "* **XGBoost:** Is **sparsity-aware**. It has a built-in routine to handle missing values. During tree construction, it learns a \"default direction\" for each node. When it encounters a missing value, it sends the data point down this learned default path, making imputation unnecessary and often more effective.\n",
    "\n",
    "#### 4. System Optimizations and Speed\n",
    "\n",
    "* **Standard GBDT:** Is typically implemented as a single-threaded process. Tree construction is purely sequential.\n",
    "* **XGBoost:** Is designed from the ground up for performance and efficiency.\n",
    "    * **Parallelization:** While the boosting process is sequential, XGBoost can parallelize the construction of individual trees. The most time-consuming part‚Äîfinding the best split for each node‚Äîis done in parallel across features.\n",
    "    * **Cache Awareness:** XGBoost uses algorithms that are aware of the CPU cache hierarchy, minimizing cache misses and speeding up calculations.\n",
    "    * **Block Structure:** Data is sorted and stored in in-memory units called \"blocks.\" This structure is used repeatedly throughout the training process, reducing computational overhead.\n",
    "\n",
    "#### 5. Tree Pruning\n",
    "\n",
    "* **Standard GBDT:** Typically grows trees up to a `max_depth` and then may perform \"post-pruning\" (cutting back branches that don't add value).\n",
    "* **XGBoost:** Uses a more integrated pruning method. It grows the tree up to `max_depth` but stops splitting a node if the split results in a negative loss change (controlled by the `gamma` parameter). This is a more efficient \"pruning-while-growing\" approach.\n",
    "\n",
    "#### 6. Built-in Cross-Validation\n",
    "\n",
    "* **Standard GBDT:** To perform cross-validation, you need to use an external library like Scikit-Learn's `GridSearchCV`.\n",
    "* **XGBoost:** Has a built-in cross-validation function (`xgb.cv()`) which is highly efficient and makes finding the optimal number of boosting rounds straightforward.\n",
    "\n",
    "---\n",
    "\n",
    "### Advantages of Each\n",
    "\n",
    "#### Advantages of GBDT (Standard Implementations like in Scikit-Learn)\n",
    "\n",
    "1.  **Simplicity and Intuitiveness:** It is the foundational algorithm. Its core logic (fitting new trees to residuals/gradients) is easier to understand and implement from scratch, making it an excellent learning tool.\n",
    "2.  **Less \"Black Box\":** Because it has fewer complex optimizations and hyperparameters, its behavior can sometimes be easier to reason about on smaller, simpler datasets.\n",
    "3.  **Wide Availability:** It's a standard part of major libraries like Scikit-Learn, making it immediately accessible without installing extra packages.\n",
    "\n",
    "#### Advantages of XGBoost\n",
    "\n",
    "1.  **Superior Performance (Accuracy):** The use of the second-order derivative (Hessian) and built-in regularization almost always leads to a more accurate, better-generalizing model.\n",
    "2.  **Exceptional Speed:** Due to its advanced system optimizations (parallelization, cache-awareness, etc.), XGBoost is significantly faster than standard GBDT implementations, especially on large datasets.\n",
    "3.  **Robustness to Overfitting:** The built-in L1/L2 regularization is a powerful tool to combat overfitting, a common problem with standard GBDT.\n",
    "4.  **Convenience and Flexibility:** Built-in features like handling missing data, cross-validation, and the ability to use custom objective functions make the entire modeling pipeline much smoother and more powerful.\n",
    "5.  **Industry Standard:** For a long time, XGBoost was the dominant algorithm in Kaggle competitions and is widely used in industry for structured/tabular data problems due to its reliable, high-performance results.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Table\n",
    "\n",
    "| Feature | Standard GBDT | XGBoost |\n",
    "| :--- | :--- | :--- |\n",
    "| **Regularization** | None (prone to overfitting) | L1 & L2 Regularization (controls complexity) |\n",
    "| **Objective Function**| 1st Derivative (Gradient) only | 1st & 2nd Derivatives (Gradient & Hessian) |\n",
    "| **Missing Values** | Requires manual imputation | Built-in, sparsity-aware handling |\n",
    "| **Performance** | Single-threaded, slower | Parallelized, cache-aware, much faster |\n",
    "| **Tree Pruning** | Post-pruning (less efficient) | Pruning during growth (`gamma` parameter) |\n",
    "| **Cross-Validation**| Requires external libraries | Built-in efficient CV function |\n",
    "| **Main Advantage** | Simplicity, foundational concept | Speed, Accuracy, and Features |"
   ],
   "id": "6daf31ac316e80ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 5. ‰ªÄ‰πàÊòØÈõÜÊàêÂ≠¶‰π†ÔºåÂÆÉÊúâ‰ªÄ‰πàÂ•ΩÂ§Ñ?\n",
    "Ensemble learning is a general machine learning technique where the predictions from multiple individual models (often called \"weak learners\") are strategically combined to produce a single, final prediction that is more accurate and robust than any of the individual models on their own.\n",
    "\n",
    "The core idea is simple: **the wisdom of the crowd is often better than the wisdom of an individual.** Instead of building and relying on one single, complex model, you build many simpler models and aggregate their outputs.\n",
    "\n",
    "---\n",
    "\n",
    "### How It Works: The Main Types of Ensemble Methods\n",
    "\n",
    "There are three primary categories of ensemble learning, each with a different strategy for combining models.\n",
    "\n",
    "#### 1. Bagging (Bootstrap Aggregating)\n",
    "\n",
    "This method focuses on **reducing variance** and preventing overfitting. It works by training multiple models of the same type in **parallel**.\n",
    "\n",
    "* **How it Works:**\n",
    "    1.  **Bootstrap:** Create many random subsamples of the training data *with replacement*. This means some data points may appear multiple times in a sample, while others may not appear at all.\n",
    "    2.  **Aggregate:** Train one model on each of these subsamples independently.\n",
    "    3.  **Combine:** The final prediction is made by averaging the predictions of all models (for regression) or by taking a majority vote (for classification).\n",
    "\n",
    "* **Key Example:** **Random Forest**. It is an ensemble of many Decision Trees, where each tree is trained on a random subset of the data and also considers only a random subset of features for each split.\n",
    "\n",
    "#### 2. Boosting\n",
    "\n",
    "This method focuses on **reducing bias** and turning a collection of weak learners into a single strong learner. It works by training models **sequentially**.\n",
    "\n",
    "* **How it Works:**\n",
    "    1.  Train a first model on the entire dataset.\n",
    "    2.  Identify the errors (misclassified data points) made by this model.\n",
    "    3.  Train a second model that pays more attention to the data points the first model got wrong.\n",
    "    4.  Repeat this process, with each new model focusing on the errors of the combined previous models.\n",
    "    5.  The final prediction is a weighted sum of the predictions from all the models.\n",
    "\n",
    "* **Key Examples:** **AdaBoost**, **Gradient Boosting Decision Trees (GBDT)**, and **XGBoost**.\n",
    "\n",
    "#### 3. Stacking (Stacked Generalization)\n",
    "\n",
    "This is a more advanced method that learns how to best combine the predictions from multiple different models.\n",
    "\n",
    "* **How it Works:**\n",
    "    1.  **Train Base Models:** Train several different types of models (e.g., a Random Forest, an SVM, and a Neural Network) on the training data. These are the \"Level 0\" models.\n",
    "    2.  **Create a New Dataset:** Use the predictions from these base models as new features.\n",
    "    3.  **Train a Meta-Model:** Train a final model, called a \"meta-model\" or \"blender\" (e.g., a Logistic Regression), on these new features (the predictions of the base models). This meta-model learns the best way to weigh the outputs of the base models.\n",
    "\n",
    "---\n",
    "\n",
    "### The Benefits of Ensemble Learning\n",
    "\n",
    "#### 1.  Improved Predictive Accuracy\n",
    "\n",
    "* This is the primary benefit. By combining the strengths of multiple models, the ensemble can cancel out their individual weaknesses. The final model's performance is almost always better than that of any single contributing model. This is why ensemble methods (especially XGBoost and LightGBM) dominate machine learning competitions for tabular data.\n",
    "\n",
    "#### 2.  Increased Robustness and Stability\n",
    "\n",
    "* An ensemble model is less sensitive to noise or variations in the training data. A single model might be heavily influenced by a few outliers or a particular random split of the data, leading to instability. An ensemble averages out these idiosyncrasies, resulting in a more stable and reliable model that generalizes better to unseen data.\n",
    "\n",
    "#### 3.  Reduction of Errors (Bias and Variance)\n",
    "\n",
    "* Ensemble methods are a powerful tool for managing the bias-variance tradeoff.\n",
    "    * **Bagging** is excellent at **reducing variance**. By training models on different data subsets and averaging their predictions, it smooths out the predictions and makes the model less likely to overfit.\n",
    "    * **Boosting** is excellent at **reducing bias**. By sequentially focusing on errors, it can build a model that is complex and powerful enough to capture the true underlying patterns in the data, which a single weak model could not.\n",
    "\n",
    "#### 4.  Ability to Capture More Complex Relationships\n",
    "\n",
    "* A single model is limited by its own assumptions and structure. An ensemble, especially a stacked one with diverse base models, can combine different \"perspectives\" on the data to learn more complex and nuanced decision boundaries than any single model could on its own."
   ],
   "id": "7af82976ad4e4b71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:03:49.210397Z",
     "start_time": "2025-10-17T14:03:49.197755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(y):\n",
    "    \"\"\"\n",
    "    ËÆ°ÁÆóÁÜµ (Entropy)\n",
    "    Entropy(S) = -sum(p_i * log2(p_i))\n",
    "    \"\"\"\n",
    "    # ÁªüËÆ°ÊØè‰∏™Á±ªÂà´ÁöÑÊï∞Èáè\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    # ËÆ°ÁÆóÊØè‰∏™Á±ªÂà´ÁöÑÊ¶ÇÁéá\n",
    "    probabilities = counts / len(y)\n",
    "    # ËÆ°ÁÆóÁÜµ\n",
    "    entropy_val = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy_val\n",
    "\n",
    "def information_gain(y_parent, y_children_list):\n",
    "    \"\"\"\n",
    "    ËÆ°ÁÆó‰ø°ÊÅØÂ¢ûÁõä (Information Gain)\n",
    "    Gain(S, A) = Entropy(S) - sum(|S_v|/|S| * Entropy(S_v))\n",
    "    \"\"\"\n",
    "    # ËÆ°ÁÆóÁà∂ËäÇÁÇπÁöÑÁÜµ\n",
    "    entropy_parent = entropy(y_parent)\n",
    "\n",
    "    # ËÆ°ÁÆóÂ≠êËäÇÁÇπÁöÑÂä†ÊùÉÁÜµ\n",
    "    num_parent = len(y_parent)\n",
    "    weighted_entropy_children = 0\n",
    "    for y_child in y_children_list:\n",
    "        weight = len(y_child) / num_parent\n",
    "        weighted_entropy_children += weight * entropy(y_child)\n",
    "\n",
    "    # ‰ø°ÊÅØÂ¢ûÁõä = Áà∂ËäÇÁÇπÁÜµ - Â≠êËäÇÁÇπÂä†ÊùÉÁÜµ\n",
    "    ig = entropy_parent - weighted_entropy_children\n",
    "    return ig\n",
    "\n",
    "# --- Á§∫‰æãÊï∞ÊçÆ: ÊòØÂê¶Âá∫ÂéªÁé© (Play Tennis) ---\n",
    "# Feature: Outlook (Sunny, Overcast, Rainy)\n",
    "# Target: Play (Yes, No)\n",
    "# ÂÅáËÆæÊàë‰ª¨Êúâ14Â§©ÁöÑÊï∞ÊçÆ\n",
    "play_data = np.array(['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No'])\n",
    "\n",
    "# ÂÅáËÆæÊàë‰ª¨Êåâ 'Outlook' ÁâπÂæÅËøõË°åÂàÜË£Ç\n",
    "# Outlook=Sunny ÁöÑ5Â§©Êï∞ÊçÆ\n",
    "play_if_sunny = np.array(['No', 'No', 'Yes', 'Yes', 'No'])\n",
    "# Outlook=Overcast ÁöÑ4Â§©Êï∞ÊçÆ\n",
    "play_if_overcast = np.array(['Yes', 'Yes', 'Yes', 'Yes']) # ËøôÊòØ‰∏Ä‰∏™Á∫ØÂáÄÁöÑÂ≠êÈõÜ\n",
    "# Outlook=Rainy ÁöÑ5Â§©Êï∞ÊçÆ\n",
    "play_if_rainy = np.array(['Yes', 'Yes', 'No', 'Yes', 'No'])\n",
    "\n",
    "# 1. ËÆ°ÁÆóÂàÜË£ÇÂâçÁöÑÊÄªÁÜµ\n",
    "parent_entropy = entropy(play_data)\n",
    "print(f\"ÂàÜË£ÇÂâçÁöÑÁà∂ËäÇÁÇπÁÜµ (Entropy): {parent_entropy:.4f}\")\n",
    "\n",
    "# 2. ËÆ°ÁÆóÊåâ 'Outlook' ÂàÜË£ÇÂêéÁöÑ‰ø°ÊÅØÂ¢ûÁõä\n",
    "ig_outlook = information_gain(play_data, [play_if_sunny, play_if_overcast, play_if_rainy])\n",
    "print(f\"Êåâ 'Outlook' ÁâπÂæÅÂàÜË£ÇÁöÑ‰ø°ÊÅØÂ¢ûÁõä (Information Gain): {ig_outlook:.4f}\")\n",
    "print(\"\\nÁªìËÆ∫: Âõ†‰∏∫‰ø°ÊÅØÂ¢ûÁõäÊòØ‰∏Ä‰∏™Ê≠£Êï∞ÔºåËØ¥ÊòéËøôÊ¨°ÂàÜË£ÇÊúâÊïàÈôç‰Ωé‰∫Ü‰∏çÁ°ÆÂÆöÊÄß„ÄÇÂÜ≥Á≠ñÊ†ë‰ºöÈÄâÊã©Â¢ûÁõäÊúÄÈ´òÁöÑÁâπÂæÅËøõË°åÂàÜË£Ç„ÄÇ\")"
   ],
   "id": "1601f377478005b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂàÜË£ÇÂâçÁöÑÁà∂ËäÇÁÇπÁÜµ (Entropy): 0.9403\n",
      "Êåâ 'Outlook' ÁâπÂæÅÂàÜË£ÇÁöÑ‰ø°ÊÅØÂ¢ûÁõä (Information Gain): 0.2467\n",
      "\n",
      "ÁªìËÆ∫: Âõ†‰∏∫‰ø°ÊÅØÂ¢ûÁõäÊòØ‰∏Ä‰∏™Ê≠£Êï∞ÔºåËØ¥ÊòéËøôÊ¨°ÂàÜË£ÇÊúâÊïàÈôç‰Ωé‰∫Ü‰∏çÁ°ÆÂÆöÊÄß„ÄÇÂÜ≥Á≠ñÊ†ë‰ºöÈÄâÊã©Â¢ûÁõäÊúÄÈ´òÁöÑÁâπÂæÅËøõË°åÂàÜË£Ç„ÄÇ\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:04:35.976171Z",
     "start_time": "2025-10-17T14:04:35.973016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gini_impurity(y):\n",
    "    \"\"\"\n",
    "    ËÆ°ÁÆóÂü∫Â∞º‰∏çÁ∫ØÂ∫¶ (Gini Impurity)\n",
    "    Gini(S) = 1 - sum(p_i^2)\n",
    "    \"\"\"\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / len(y)\n",
    "    # ËÆ°ÁÆóÂü∫Â∞ºÊåáÊï∞\n",
    "    gini = 1 - np.sum(probabilities**2)\n",
    "    return gini\n",
    "\n",
    "# Âú∫ÊôØ1: Á∫ØÂáÄÁöÑËäÇÁÇπ (Pure Node)\n",
    "# ÊâÄÊúâÊ†∑Êú¨ÈÉΩÂ±û‰∫éÂêå‰∏ÄÁ±ªÂà´\n",
    "pure_node = np.array(['Yes', 'Yes', 'Yes', 'Yes', 'Yes'])\n",
    "gini_pure = gini_impurity(pure_node)\n",
    "print(f\"Á∫ØÂáÄËäÇÁÇπÁöÑÂü∫Â∞ºÊåáÊï∞: {gini_pure:.4f} (ÂÄº‰∏∫0‰ª£Ë°®ÂÆåÂÖ®Á∫ØÂáÄ)\")\n",
    "\n",
    "# Âú∫ÊôØ2: ÂÆåÂÖ®‰∏çÁ∫ØÁöÑËäÇÁÇπ (Maximally Impure Node)\n",
    "# Á±ªÂà´ÂêÑÂç†‰∏ÄÂçä (ÂØπ‰∫é‰∫åÂàÜÁ±ªÈóÆÈ¢ò)\n",
    "impure_node = np.array(['Yes', 'Yes', 'Yes', 'No', 'No', 'No'])\n",
    "gini_impure = gini_impurity(impure_node)\n",
    "print(f\"ÂÆåÂÖ®‰∏çÁ∫ØËäÇÁÇπÁöÑÂü∫Â∞ºÊåáÊï∞: {gini_impure:.4f} (ÂÄº‰∏∫0.5‰ª£Ë°®ÂÆåÂÖ®‰∏çÁ∫Ø)\")\n",
    "\n",
    "# Âú∫ÊôØ3: ÊØîËæÉ‰∏çÁ∫ØÁöÑËäÇÁÇπ (Moderately Impure Node)\n",
    "mixed_node = np.array(['Yes', 'Yes', 'Yes', 'Yes', 'No'])\n",
    "gini_mixed = gini_impurity(mixed_node)\n",
    "print(f\"ÊØîËæÉ‰∏çÁ∫ØËäÇÁÇπÁöÑÂü∫Â∞ºÊåáÊï∞: {gini_mixed:.4f} (ÂÄº‰ªã‰∫é0Âíå0.5‰πãÈó¥)\")"
   ],
   "id": "b993ce55caf0869e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Á∫ØÂáÄËäÇÁÇπÁöÑÂü∫Â∞ºÊåáÊï∞: 0.0000 (ÂÄº‰∏∫0‰ª£Ë°®ÂÆåÂÖ®Á∫ØÂáÄ)\n",
      "ÂÆåÂÖ®‰∏çÁ∫ØËäÇÁÇπÁöÑÂü∫Â∞ºÊåáÊï∞: 0.5000 (ÂÄº‰∏∫0.5‰ª£Ë°®ÂÆåÂÖ®‰∏çÁ∫Ø)\n",
      "ÊØîËæÉ‰∏çÁ∫ØËäÇÁÇπÁöÑÂü∫Â∞ºÊåáÊï∞: 0.3200 (ÂÄº‰ªã‰∫é0Âíå0.5‰πãÈó¥)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:04:54.801893Z",
     "start_time": "2025-10-17T14:04:54.579977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# --- 1. ÂàõÂª∫‰∏Ä‰∫õÁ§∫‰æãÊï∞ÊçÆ ---\n",
    "np.random.seed(42)\n",
    "X = np.linspace(-5, 5, 100).reshape(-1, 1)\n",
    "y = X.ravel()**2 + np.random.normal(0, 5, 100) # ‰∏Ä‰∏™‰∫åÊ¨°ÂáΩÊï∞ÂÖ≥Á≥ª\n",
    "\n",
    "# --- GBDT Á¨¨‰∏ÄÊ≠•: ËÆ≠ÁªÉ‰∏Ä‰∏™ÂàùÂßãÊ®°Âûã F0 ---\n",
    "# ÂàùÂßãÊ®°ÂûãÈÄöÂ∏∏ÊòØÁõÆÊ†áÂÄºÁöÑÂùáÂÄº\n",
    "f0 = np.mean(y)\n",
    "print(f\"ÂàùÂßãÊ®°Âûã F0 ÁöÑÈ¢ÑÊµãÂÄº (ÊâÄÊúâÊ†∑Êú¨ÈÉΩ‰∏ÄÊ†∑): {f0:.4f}\")\n",
    "\n",
    "# --- GBDT Á¨¨‰∫åÊ≠•: ËÆ°ÁÆóÊÆãÂ∑Æ (Ë¥üÊ¢ØÂ∫¶) ---\n",
    "# Residuals = Actual - Prediction\n",
    "residuals1 = y - f0\n",
    "\n",
    "# --- GBDT Á¨¨‰∏âÊ≠•: ËÆ≠ÁªÉÁ¨¨‰∏ÄÊ£µÊ†ë h1 Êù•ÊãüÂêàÊÆãÂ∑Æ ---\n",
    "h1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "h1.fit(X, residuals1)\n",
    "\n",
    "# --- GBDT Á¨¨ÂõõÊ≠•: Êõ¥Êñ∞Ê®°Âûã F1 = F0 + learning_rate * h1 ---\n",
    "learning_rate = 0.1\n",
    "f1 = f0 + learning_rate * h1.predict(X)\n",
    "\n",
    "# --- ÂèØËßÜÂåñ ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(X, y, label='Actual Data', alpha=0.6)\n",
    "plt.axhline(f0, color='red', linestyle='--', label='F0 (Initial Mean Prediction)')\n",
    "plt.plot(X, f1, color='green', linewidth=2, label='F1 (After One Tree)')\n",
    "plt.title(\"GBDT: First Step Illustration\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nËßÇÂØüÂõæÂÉè: ÁªøËâ≤Á∫ø F1 ÊØîÁ∫¢Ëâ≤Á∫ø F0 Êõ¥Êé•ËøëÁúüÂÆûÊï∞ÊçÆÂàÜÂ∏É„ÄÇ\")\n",
    "print(\"GBDT‰ºöÁªßÁª≠ËÆ°ÁÆó F1 ÁöÑÊÆãÂ∑ÆÔºåÂπ∂ËÆ≠ÁªÉÁ¨¨‰∫åÊ£µÊ†ë h2 Êù•ÊãüÂêàÊñ∞ÁöÑÊÆãÂ∑ÆÔºå‰∏çÊñ≠Ëø≠‰ª£„ÄÇ\")"
   ],
   "id": "5388bcca50604d59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂàùÂßãÊ®°Âûã F0 ÁöÑÈ¢ÑÊµãÂÄº (ÊâÄÊúâÊ†∑Êú¨ÈÉΩ‰∏ÄÊ†∑): 7.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ËßÇÂØüÂõæÂÉè: ÁªøËâ≤Á∫ø F1 ÊØîÁ∫¢Ëâ≤Á∫ø F0 Êõ¥Êé•ËøëÁúüÂÆûÊï∞ÊçÆÂàÜÂ∏É„ÄÇ\n",
      "GBDT‰ºöÁªßÁª≠ËÆ°ÁÆó F1 ÁöÑÊÆãÂ∑ÆÔºåÂπ∂ËÆ≠ÁªÉÁ¨¨‰∫åÊ£µÊ†ë h2 Êù•ÊãüÂêàÊñ∞ÁöÑÊÆãÂ∑ÆÔºå‰∏çÊñ≠Ëø≠‰ª£„ÄÇ\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:06:45.863776Z",
     "start_time": "2025-10-17T14:06:01.845484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# --- 1. ÂàõÂª∫‰∏Ä‰∏™ËæÉÂ§ßÁöÑÊï∞ÊçÆÈõÜÊù•ÂØπÊØîÈÄüÂ∫¶ ---\n",
    "X, y = make_classification(n_samples=50000, n_features=50, n_informative=20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# --- ÂØπÊØîËÆ≠ÁªÉÈÄüÂ∫¶ ---\n",
    "# a. Scikit-learn GBDT\n",
    "print(\"--- ËÆ≠ÁªÉÈÄüÂ∫¶ÂØπÊØî ---\")\n",
    "start_time = time.time()\n",
    "gbdt = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gbdt.fit(X_train, y_train)\n",
    "gbdt_time = time.time() - start_time\n",
    "print(f\"Scikit-learn GBDT ËÆ≠ÁªÉËÄóÊó∂: {gbdt_time:.4f} Áßí\")\n",
    "\n",
    "# b. XGBoost\n",
    "start_time = time.time()\n",
    "xgboost = xgb.XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgboost.fit(X_train, y_train)\n",
    "xgboost_time = time.time() - start_time\n",
    "print(f\"XGBoost ËÆ≠ÁªÉËÄóÊó∂: {xgboost_time:.4f} Áßí\")\n",
    "\n",
    "\n",
    "# --- 2. ÂØπÊØîÁº∫Â§±ÂÄºÂ§ÑÁêÜËÉΩÂäõ ---\n",
    "print(\"\\n--- Áº∫Â§±ÂÄºÂ§ÑÁêÜËÉΩÂäõÂØπÊØî ---\")\n",
    "X_with_nan = X_train.copy()\n",
    "# ‰∫∫‰∏∫Âà∂ÈÄ†‰∏Ä‰∫õÁº∫Â§±ÂÄº\n",
    "X_with_nan[0, 0] = np.nan\n",
    "X_with_nan[5, 10] = np.nan\n",
    "\n",
    "# a. Scikit-learn GBDT\n",
    "try:\n",
    "    gbdt.fit(X_with_nan, y_train)\n",
    "except ValueError as e:\n",
    "    print(f\"Scikit-learn GBDT ÈÅáÂà∞Áº∫Â§±ÂÄºÊó∂Êä•Èîô: {e}\")\n",
    "\n",
    "# b. XGBoost\n",
    "try:\n",
    "    xgboost.fit(X_with_nan, y_train)\n",
    "    print(\"XGBoost ÊàêÂäüÂ§ÑÁêÜ‰∫ÜÂê´ÊúâÁº∫Â§±ÂÄºÁöÑÊï∞ÊçÆÂπ∂ÂÆåÊàêËÆ≠ÁªÉ„ÄÇ\")\n",
    "except Exception as e:\n",
    "    print(f\"XGBoost ÈÅáÂà∞Áº∫Â§±ÂÄºÊó∂Êä•Èîô: {e}\")"
   ],
   "id": "70e9ad740c2f397f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ËÆ≠ÁªÉÈÄüÂ∫¶ÂØπÊØî ---\n",
      "Scikit-learn GBDT ËÆ≠ÁªÉËÄóÊó∂: 42.3717 Áßí\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mapleandrew/.pyenv/versions/3.12.10/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [22:06:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost ËÆ≠ÁªÉËÄóÊó∂: 0.3794 Áßí\n",
      "\n",
      "--- Áº∫Â§±ÂÄºÂ§ÑÁêÜËÉΩÂäõÂØπÊØî ---\n",
      "Scikit-learn GBDT ÈÅáÂà∞Áº∫Â§±ÂÄºÊó∂Êä•Èîô: Input X contains NaN.\n",
      "GradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mapleandrew/.pyenv/versions/3.12.10/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [22:06:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost ÊàêÂäüÂ§ÑÁêÜ‰∫ÜÂê´ÊúâÁº∫Â§±ÂÄºÁöÑÊï∞ÊçÆÂπ∂ÂÆåÊàêËÆ≠ÁªÉ„ÄÇ\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:07:01.493062Z",
     "start_time": "2025-10-17T14:07:01.351328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- ÂàõÂª∫Êï∞ÊçÆÈõÜ ---\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=5, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# --- Ê®°Âûã1: Âçï‰∏™ÂÜ≥Á≠ñÊ†ë (Âº±Â≠¶‰π†Âô®) ---\n",
    "single_tree = DecisionTreeClassifier(random_state=42)\n",
    "single_tree.fit(X_train, y_train)\n",
    "y_pred_tree = single_tree.predict(X_test)\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "print(f\"Âçï‰∏™ÂÜ≥Á≠ñÊ†ëÁöÑÂáÜÁ°ÆÁéá: {accuracy_tree:.4f}\")\n",
    "\n",
    "# --- Ê®°Âûã2: ÈöèÊú∫Ê£ÆÊûó (ÈõÜÊàêÊ®°Âûã) ---\n",
    "# ÈöèÊú∫Ê£ÆÊûóÊòØ100Ê£µÂÜ≥Á≠ñÊ†ëÁöÑÈõÜÊàê\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"ÈöèÊú∫Ê£ÆÊûó (100Ê£µÊ†ëÁöÑÈõÜÊàê) ÁöÑÂáÜÁ°ÆÁéá: {accuracy_rf:.4f}\")\n",
    "\n",
    "print(\"\\nÁªìËÆ∫: ÈõÜÊàêÊ®°Âûã(ÈöèÊú∫Ê£ÆÊûó)ÁöÑÊÄßËÉΩÈÄöÂ∏∏ÊòæËëó‰ºò‰∫éÂÖ∂ÂÜÖÈÉ®ÁöÑ‰ªª‰ΩïÂçï‰∏™Ê®°Âûã(ÂÜ≥Á≠ñÊ†ë)„ÄÇ\")"
   ],
   "id": "649537d088ad07bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Âçï‰∏™ÂÜ≥Á≠ñÊ†ëÁöÑÂáÜÁ°ÆÁéá: 0.8167\n",
      "ÈöèÊú∫Ê£ÆÊûó (100Ê£µÊ†ëÁöÑÈõÜÊàê) ÁöÑÂáÜÁ°ÆÁéá: 0.9167\n",
      "\n",
      "ÁªìËÆ∫: ÈõÜÊàêÊ®°Âûã(ÈöèÊú∫Ê£ÆÊûó)ÁöÑÊÄßËÉΩÈÄöÂ∏∏ÊòæËëó‰ºò‰∫éÂÖ∂ÂÜÖÈÉ®ÁöÑ‰ªª‰ΩïÂçï‰∏™Ê®°Âûã(ÂÜ≥Á≠ñÊ†ë)„ÄÇ\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c439fe98ee7ecd8f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
